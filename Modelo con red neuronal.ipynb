{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, Flatten, Conv1D, GlobalMaxPooling1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Lee el archivo de Excel con dos columnas (texto y etiqueta)\n",
    "\n",
    "df = pd.read_excel('cluster.xlsx')\n",
    "\n",
    "# Separa las columnas de datos y etiquetas\n",
    "df['Data'] = df['Data'].astype(str)\n",
    "datos = df['Data'].tolist()\n",
    "etiquetas = df['Etiqueta'].tolist()\n",
    "\n",
    "# Preprocesamiento de datos\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(datos)\n",
    "sequences = tokenizer.texts_to_sequences(datos)\n",
    "word_index = tokenizer.word_index\n",
    "maxlen = 100\n",
    "data = pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "\n",
    "# Codifica las etiquetas de texto a números\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(etiquetas)\n",
    "labels = np.asarray(labels)\n",
    "\n",
    "# Separa los datos en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Crea el modelo\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(word_index) + 1, output_dim=128, input_length=maxlen))\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(60, activation='softmax'))\n",
    "\n",
    "# Compila el modelo\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Convierte las etiquetas a codificación one-hot\n",
    "y_train = np.eye(60)[y_train]\n",
    "y_test = np.eye(60)[y_test]\n",
    "\n",
    "# Entrena el modelo\n",
    "model.fit(X_train, y_train, epochs=15, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Evalúa el modelo en el conjunto de prueba\n",
    "score, acc = model.evaluate(X_test, y_test, batch_size=64)\n",
    "print(\"Precisión del modelo: {:.2f}%\".format(acc * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
